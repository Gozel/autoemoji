{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "def readFacialExpression():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    w = cap.get(cv2.CAP_PROP_FRAME_WIDTH);\n",
    "    h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT); \n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc('d','i','v','x')\n",
    "    out = cv2.VideoWriter('output.avi',fourcc, 25.0, (int(w),int(h)))\n",
    "    #out = cv2.VideoWriter('output.avi', -1, 20.0, (640,480))\n",
    "\n",
    "    timeInit = time.time()\n",
    "    # only record for 200 ms \n",
    "    while(cap.isOpened() & (500 > ((time.time() - timeInit)*1000))):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "            #frame = cv2.flip(frame,0)\n",
    "            # write the flipped frame\n",
    "            out.write(frame)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFacialFeatures(ffile):\n",
    "\n",
    "    return 0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# snapshot used as input to trained classifier (e.g., scikit.svm.predict(snapshot)). \n",
    "# returns label (happy, sad, neutral, angry)\n",
    "def classifyFacialExpression():\n",
    "    \n",
    "    readFacialExpression()\n",
    "    HOGs_list = []\n",
    "    Cs_list = []\n",
    "    best_list = []\n",
    "    \n",
    "    cap = cv2.VideoCapture('output.avi')\n",
    "    \n",
    "    print int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    for i in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        pil_im = Image.fromarray(frame)\n",
    "        \n",
    "        # pass resizedFrame to a-boooody's classifier\n",
    "        HOGs, Cs, bestFrame = extractFacialFeatures(frame)\n",
    "        \n",
    "        HOGs_list.append(HOGs)\n",
    "        Cs_list.append(Cs)\n",
    "        best_list.append(bestFrame)\n",
    "    \n",
    "    ## filter according to some criterion and find the  best image! \n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return bestFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifyFacialExpression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
